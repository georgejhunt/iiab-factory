{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dirty-snake",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modifying ZIM Files\n",
    "\n",
    "#### The Larger Picture\n",
    "* Kiwix scrapes many useful sources, but sometimes the chunks are too big for IIAB.\n",
    "* Using the zimdump program, the highly compressed ZIM files can be flattened into a file tree, modified, and then re-packaged as a ZIM file.\n",
    "* This Notebook has a collection of tools which filters the content into a new smaller zim selected by youtube views/per year.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-scotland",
   "metadata": {},
   "source": [
    "#### How to Use this notebook\n",
    "* The zimdump program (at https://github.com/openzim/zim-tools) needs to be compiled from source.\n",
    "* A bash script makes is easy to compile zimtools (which contains zimdump) on Ubuntu 20.04. There are instructions for the compilation at the github url. In a terminal, do the following:\n",
    "\n",
    "```\n",
    "cd /opt/iiab/iiab-factory/content/kiwix/generic/ \n",
    "sudo ./install-zim-tools.sh\n",
    "\n",
    "```\n",
    "* This ```zimfilter``` program can be set up into a python virtual environment using a role in the iiab-factory repository:\n",
    "\n",
    "```\n",
    "sudo ./runrole youtube\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-pierce",
   "metadata": {},
   "source": [
    "* **Some conventions**: Jupyter does not want to run as root. We will create a file structure that exists in the users home directory -- so the application will be able to write all the files it needs to function.\n",
    "```\n",
    "<PREFIX><project name>\n",
    "├── default_config.yaml\n",
    "├── new-zim\n",
    "├── output_tree\n",
    "├── proof\n",
    "├── tree\n",
    "├── working\n",
    "└── zim-src\n",
    "```\n",
    "In general terms, this program will dump the zim data into \"tree\", modify it, gather additional data into \"working\", copy the desired videos to \"output_tree\"\n",
    ", and create a ZIM file in \"new_zim\". After the new ZIM is created, it is re-dumped to \"proof\".\n",
    "* For testing purposes, the user will need to link from the server's document root to her home directory (so that the nginx http server in IIAB will serve the candidate in \"tree):\n",
    "\n",
    "```\n",
    "cd\n",
    "mkdir -p zims\n",
    "ln -s /home/<user name>/zims/library/www/html/zims \n",
    "```\n",
    "**Note**: At the bottom of this notebook there is information about installing jupyterhub on VirtualBox."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-punch",
   "metadata": {},
   "source": [
    "#### Declare input\n",
    "* We let the Admin Console download the source ZIM to /library/zims/content\n",
    "* There may be other ZIM files in /library/zims/content.\n",
    "* Choose a string in the ZIM file you want to process that is not contained in any other ZIMs in /library/zims/content and write that string to \"current_project\".\n",
    "* This string will be used to create a set of folders as described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "analyzed-breakfast",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "import os,sys\n",
    "import json\n",
    "import youtube_dl\n",
    "import pprint as pprint\n",
    "from types import SimpleNamespace\n",
    "import subprocess\n",
    "from ruamel.yaml import YAML \n",
    "from pprint import pprint\n",
    "\n",
    "# Get the current project from it's pointer in iiab-factory repo\n",
    "FACTORY_REPO = '/opt/iiab/iiab-factory'\n",
    "PREFIX = '/library/www/html/zims'\n",
    "#PREFIX = '/ext/zims'\n",
    "\n",
    "current_project = FACTORY_REPO + '/content/kiwix/zim-filter/current_project'\n",
    "if not os.path.isfile(current_project):\n",
    "    print(f'\\\"current_project\\\" file is missing: {current_project}')\n",
    "    sys.exit(1)\n",
    "with open(current_project,'r') as fp:\n",
    "    project_name = fp.read().strip().split('/')\n",
    "    if len(project_name) > 0:\n",
    "        prefix = project_name[:-1]\n",
    "        project_name = project_name[-1]\n",
    "lookfor = f\"{PREFIX}/{project_name}/default_config.yaml\"\n",
    "dflt_cfg = f'{FACTORY_REPO}/content/kiwix/zim-filter/default_filter.yaml'\n",
    "yml = YAML()\n",
    "if not os.path.isfile(lookfor):\n",
    "    with open(dflt_cfg,'r') as fp:\n",
    "        cfg = yml.load(fp)\n",
    "    cfg['PREFIX'] = PREFIX\n",
    "    cfg['PROJECT_NAME'] = project_name\n",
    "    if not os.path.isdir(PREFIX + '/' + project_name):\n",
    "       os.makedirs(PREFIX + '/' + project_name)\n",
    "    with open(lookfor,'w') as newfp:\n",
    "        yml.dump(cfg,newfp) \n",
    "else:\n",
    "    with open(lookfor,'r') as fp:\n",
    "        cfg = yml.load(fp)\n",
    "\n",
    "PROJECT_NAME = cfg['PROJECT_NAME']\n",
    "SOURCE_URL = cfg['SOURCE_URL']\n",
    "CACHE_DIR = PREFIX + '/youtube/cache'\n",
    "if not os.path.isdir(CACHE_DIR):\n",
    "   os.makedirs(CACHE_DIR)\n",
    "TARGET_SIZE = cfg['TARGET_SIZE']  #10GB\n",
    "\n",
    "# The rest of the paths are computed and represent the standard layout\n",
    "WORKING_DIR = PREFIX + '/' + PROJECT_NAME + '/working'\n",
    "PROJECT_DIR = PREFIX + '/' + PROJECT_NAME + '/tree'\n",
    "OUTPUT_DIR = PREFIX + '/' + PROJECT_NAME + '/output_tree'\n",
    "SOURCE_DIR = PREFIX + '/' + PROJECT_NAME + '/zim-src'\n",
    "NEW_ZIM_DIR = PREFIX + '/' + PROJECT_NAME + '/new-zim'\n",
    "PROOF_DIR = PREFIX + '/' + PROJECT_NAME + '/proof'\n",
    "dir_list = ['working','output_tree','tree','../youtube/cache/video_json','zim-src','new-zim','proof']\n",
    "for f in dir_list: \n",
    "    if not os.path.isdir(PREFIX + '/' + PROJECT_NAME +'/' + f):\n",
    "       os.makedirs(PREFIX + '/' + PROJECT_NAME +'/' + f)\n",
    "\n",
    "# If this is not first filter of this zim, let cfg file specify source \n",
    "if SOURCE_URL != '':\n",
    "    ZIM_PATH = SOURCE_URL\n",
    "    cmd = 'wget -P %s %s'%(SOURCE_DIR,SOURCE_URL)\n",
    "    print('command:%s'%cmd)\n",
    "    subprocess.run(cmd,shell=True)\n",
    "else:\n",
    "    # pick the downloaded ZIM which contains <project> string       \n",
    "    zim_path_contents = os.listdir('/library/zims/content')\n",
    "    for zim in zim_path_contents:\n",
    "        if zim.find(PROJECT_NAME) != -1:\n",
    "            zim_file = '/library/zims/content/%s'%(zim)\n",
    "            if not os.path.exists(f'{SOURCE_DIR}/{zim}'):\n",
    "                os.symlink(zim_file,f'{SOURCE_DIR}/{zim}')\n",
    "            ZIM_PATH = f'{SOURCE_DIR}/{zim}'\n",
    "# abort if the input file cannot be found\n",
    "if not os.path.exists(ZIM_PATH):\n",
    "    print('%s path not found. Quitting. . .'%ZIM_PATH)\n",
    "    exit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alert-cowboy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/library/www/html/zims,/library/www/html/zims/trippy/tree,trippy\n"
     ]
    }
   ],
   "source": [
    "print(f'{PREFIX},{PROJECT_DIR},{project_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cloudy-mount",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using zimdump to expand the zim file to /library/www/html/zims/trippy/tree\n",
      "command:/opt/iiab/iiab-factory/content/kiwix/zim-filter/de-namespace.sh /library/www/html/zims/trippy/zim-src/ted_en_playlist-9-trippy-ted-talks_2021-01.zim /library/www/html/zims/trippy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='/opt/iiab/iiab-factory/content/kiwix/zim-filter/de-namespace.sh /library/www/html/zims/trippy/zim-src/ted_en_playlist-9-trippy-ted-talks_2021-01.zim /library/www/html/zims/trippy', returncode=0, stdout=b'', stderr=b\"+ set -e\\n+ '[' 2 -lt 2 ']'\\n+ '[' '!' -f /library/www/html/zims/trippy/zim-src/ted_en_playlist-9-trippy-ted-talks_2021-01.zim ']'\\n++ ls /library/www/html/zims/trippy/tree\\n++ wc -l\\n+ contents=0\\n+ '[' 0 -ne 0 ']'\\n+ rm -rf /library/www/html/zims/trippy/tree\\n+ mkdir -p /library/www/html/zims/trippy/tree\\n+ echo 'This de-namespace file reminds you that this folder will be overwritten?'\\n+ zimdump dump --dir=/library/www/html/zims/trippy/tree /library/www/html/zims/trippy/zim-src/ted_en_playlist-9-trippy-ted-talks_2021-01.zim\\n+ mv /library/www/html/zims/trippy/tree/I/assets /library/www/html/zims/trippy/tree/I/favicon.png /library/www/html/zims/trippy/tree/I/videos /library/www/html/zims/trippy/tree\\n+ '[' -d I ']'\\n+ cp -rp /library/www/html/zims/trippy/tree/A/a-dance-of-symbiosis /library/www/html/zims/trippy/tree/A/a-musical-escape-into-a-world-of-light-and-color /library/www/html/zims/trippy/tree/A/are-you-human /library/www/html/zims/trippy/tree/A/a-scientific-approach-to-the-paranormal /library/www/html/zims/trippy/tree/A/assets /library/www/html/zims/trippy/tree/A/beats-that-defy-boxes /library/www/html/zims/trippy/tree/A/dance-tiny-robots /library/www/html/zims/trippy/tree/A/dancing-with-light /library/www/html/zims/trippy/tree/A/i-listen-to-color /library/www/html/zims/trippy/tree/A/index /library/www/html/zims/trippy/tree/A/my-mushroom-burial-suit /library/www/html/zims/trippy/tree/A/psychedelic-science /library/www/html/zims/trippy/tree/A/your-body-is-my-canvas /library/www/html/zims/trippy/tree\\n+ cp -rp /library/www/html/zims/trippy/tree/-/assets /library/www/html/zims/trippy/tree/-/favicon /library/www/html/zims/trippy/tree/-/videos /library/www/html/zims/trippy/tree\\n+ '[' -d /library/www/html/zims/trippy/tree/A ']'\\n+ rm -rf /library/www/html/zims/trippy/tree/A\\n+ cd /library/www/html/zims/trippy/tree\\n++ find .\\n++ grep -e html -e css\\n+ for f in $(find .|grep -e html -e css )\\n+ sed -i '-es|../../../I/||g' ./-/assets/videojs/video-js.css\\n+ sed -i '-es|../../I/||g' ./-/assets/videojs/video-js.css\\n+ sed -i '-es|../I/||g' ./-/assets/videojs/video-js.css\\n+ sed -i '-es|../../-/||g' ./-/assets/videojs/video-js.css\\n+ sed -i '-es|../A/||g' ./-/assets/videojs/video-js.css\\n+ for f in $(find .|grep -e html -e css )\\n+ sed -i '-es|../../../I/||g' ./-/assets/videojs/video-js.min.css\\n+ sed -i '-es|../../I/||g' ./-/assets/videojs/video-js.min.css\\n+ sed -i '-es|../I/||g' ./-/assets/videojs/video-js.min.css\\n+ sed -i '-es|../../-/||g' ./-/assets/videojs/video-js.min.css\\n+ sed -i '-es|../A/||g' ./-/assets/videojs/video-js.min.css\\n+ for f in $(find .|grep -e html -e css )\\n+ sed -i '-es|../../../I/||g' ./-/assets/article.css\\n+ sed -i '-es|../../I/||g' ./-/assets/article.css\\n+ sed -i '-es|../I/||g' ./-/assets/article.css\\n+ sed -i '-es|../../-/||g' ./-/assets/article.css\\n+ sed -i '-es|../A/||g' ./-/assets/article.css\\n+ for f in $(find .|grep -e html -e css )\\n+ sed -i '-es|../../../I/||g' ./-/assets/chosen/chosen.css\\n+ sed -i '-es|../../I/||g' ./-/assets/chosen/chosen.css\\n+ sed -i '-es|../I/||g' ./-/assets/chosen/chosen.css\\n+ sed -i '-es|../../-/||g' ./-/assets/chosen/chosen.css\\n+ sed -i '-es|../A/||g' ./-/assets/chosen/chosen.css\\n+ for f in $(find .|grep -e html -e css )\\n+ sed -i '-es|../../../I/||g' ./-/assets/chosen/chosen.min.css\\n+ sed -i '-es|../../I/||g' ./-/assets/chosen/chosen.min.css\\n+ sed -i '-es|../I/||g' ./-/assets/chosen/chosen.min.css\\n+ sed -i '-es|../../-/||g' ./-/assets/chosen/chosen.min.css\\n+ sed -i '-es|../A/||g' ./-/assets/chosen/chosen.min.css\\n+ for f in $(find .|grep -e html -e css )\\n+ sed -i '-es|../../../I/||g' ./-/assets/home.css\\n+ sed -i '-es|../../I/||g' ./-/assets/home.css\\n+ sed -i '-es|../I/||g' ./-/assets/home.css\\n+ sed -i '-es|../../-/||g' ./-/assets/home.css\\n+ sed -i '-es|../A/||g' ./-/assets/home.css\\n+ for f in $(find .|grep -e html -e css )\\n+ sed -i '-es|../../../I/||g' ./assets/videojs/video-js.css\\n+ sed -i '-es|../../I/||g' ./assets/videojs/video-js.css\\n+ sed -i '-es|../I/||g' ./assets/videojs/video-js.css\\n+ sed -i '-es|../../-/||g' ./assets/videojs/video-js.css\\n+ sed -i '-es|../A/||g' ./assets/videojs/video-js.css\\n+ for f in $(find .|grep -e html -e css )\\n+ sed -i '-es|../../../I/||g' ./assets/videojs/video-js.min.css\\n+ sed -i '-es|../../I/||g' ./assets/videojs/video-js.min.css\\n+ sed -i '-es|../I/||g' ./assets/videojs/video-js.min.css\\n+ sed -i '-es|../../-/||g' ./assets/videojs/video-js.min.css\\n+ sed -i '-es|../A/||g' ./assets/videojs/video-js.min.css\\n+ for f in $(find .|grep -e html -e css )\\n+ sed -i '-es|../../../I/||g' ./assets/article.css\\n+ sed -i '-es|../../I/||g' ./assets/article.css\\n+ sed -i '-es|../I/||g' ./assets/article.css\\n+ sed -i '-es|../../-/||g' ./assets/article.css\\n+ sed -i '-es|../A/||g' ./assets/article.css\\n+ for f in $(find .|grep -e html -e css )\\n+ sed -i '-es|../../../I/||g' ./assets/chosen/chosen.css\\n+ sed -i '-es|../../I/||g' ./assets/chosen/chosen.css\\n+ sed -i '-es|../I/||g' ./assets/chosen/chosen.css\\n+ sed -i '-es|../../-/||g' ./assets/chosen/chosen.css\\n+ sed -i '-es|../A/||g' ./assets/chosen/chosen.css\\n+ for f in $(find .|grep -e html -e css )\\n+ sed -i '-es|../../../I/||g' ./assets/chosen/chosen.min.css\\n+ sed -i '-es|../../I/||g' ./assets/chosen/chosen.min.css\\n+ sed -i '-es|../I/||g' ./assets/chosen/chosen.min.css\\n+ sed -i '-es|../../-/||g' ./assets/chosen/chosen.min.css\\n+ sed -i '-es|../A/||g' ./assets/chosen/chosen.min.css\\n+ for f in $(find .|grep -e html -e css )\\n+ sed -i '-es|../../../I/||g' ./assets/home.css\\n+ sed -i '-es|../../I/||g' ./assets/home.css\\n+ sed -i '-es|../I/||g' ./assets/home.css\\n+ sed -i '-es|../../-/||g' ./assets/home.css\\n+ sed -i '-es|../A/||g' ./assets/home.css\\n++ find /library/www/html/zims/trippy/tree -maxdepth 1 -type f\\n+ for f in $(find $2/tree -maxdepth 1 -type f )\\n+ sed -i '-es|../-/||g' /library/www/html/zims/trippy/tree/i-listen-to-color\\n+ for f in $(find $2/tree -maxdepth 1 -type f )\\n+ sed -i '-es|../-/||g' /library/www/html/zims/trippy/tree/my-mushroom-burial-suit\\n+ for f in $(find $2/tree -maxdepth 1 -type f )\\n+ sed -i '-es|../-/||g' /library/www/html/zims/trippy/tree/dance-tiny-robots\\n+ for f in $(find $2/tree -maxdepth 1 -type f )\\n+ sed -i '-es|../-/||g' /library/www/html/zims/trippy/tree/your-body-is-my-canvas\\n+ for f in $(find $2/tree -maxdepth 1 -type f )\\n+ sed -i '-es|../-/||g' /library/www/html/zims/trippy/tree/favicon.png\\n+ for f in $(find $2/tree -maxdepth 1 -type f )\\n+ sed -i '-es|../-/||g' /library/www/html/zims/trippy/tree/a-scientific-approach-to-the-paranormal\\n+ for f in $(find $2/tree -maxdepth 1 -type f )\\n+ sed -i '-es|../-/||g' /library/www/html/zims/trippy/tree/index\\n+ for f in $(find $2/tree -maxdepth 1 -type f )\\n+ sed -i '-es|../-/||g' /library/www/html/zims/trippy/tree/are-you-human\\n+ for f in $(find $2/tree -maxdepth 1 -type f )\\n+ sed -i '-es|../-/||g' /library/www/html/zims/trippy/tree/dancing-with-light\\n+ for f in $(find $2/tree -maxdepth 1 -type f )\\n+ sed -i '-es|../-/||g' /library/www/html/zims/trippy/tree/beats-that-defy-boxes\\n+ for f in $(find $2/tree -maxdepth 1 -type f )\\n+ sed -i '-es|../-/||g' /library/www/html/zims/trippy/tree/psychedelic-science\\n+ for f in $(find $2/tree -maxdepth 1 -type f )\\n+ sed -i '-es|../-/||g' /library/www/html/zims/trippy/tree/a-dance-of-symbiosis\\n+ for f in $(find $2/tree -maxdepth 1 -type f )\\n+ sed -i '-es|../-/||g' /library/www/html/zims/trippy/tree/de-namespace\\n+ for f in $(find $2/tree -maxdepth 1 -type f )\\n+ sed -i '-es|../-/||g' /library/www/html/zims/trippy/tree/a-musical-escape-into-a-world-of-light-and-color\\n\")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following command will zimdump to the \"tree\" directory\n",
    "#  Despite the name, removing namespaces seems unnecessary, and more complex\n",
    "# It will return without doing anything if the \"tree' is not empty\n",
    "print('Using zimdump to expand the zim file to %s'%PROJECT_DIR)\n",
    "progname = '%s/content/kiwix/zim-filter/de-namespace.sh'%(cfg['FACTORY_REPO'])\n",
    "cmd = \"%s %s %s\"%(progname,ZIM_PATH,PREFIX + '/' + PROJECT_NAME)\n",
    "print('command:%s'%cmd)\n",
    "subprocess.run(cmd,shell=True,capture_output=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-contributor",
   "metadata": {},
   "source": [
    "* The next step is a manual one that you will need to do with your browser. That is: to verify that after the namespace directories were removed, and all of the html links have been adjusted correctly. Point your browser to <hostname>/zims/\\<PROJECT_NAME\\>/tree.\n",
    "* If everything is working, it's time to go fetch the information about each video from youtube."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-representative",
   "metadata": {},
   "source": [
    "#### Unfortunate choices by Kiwix\n",
    "* The first few youtube ZIMs I examined used the 11 character Youtube_id as the directory name where the video was stored, and also the link in the ```data.js``` file which links categories to the videos themselves.\n",
    "* But some ZIM's use random numbers (unknown origin) as the video identity and  link.\n",
    "* We need the actual Youbube_id in order to get the views per year which we use to select which videos to include in the output ZIM. -- So we use a search function in the youtube Google API to look up the unique 11 character id.\n",
    "* Google charges 100 units of funny money to do a search, and allocates 10000 units to a developer per day. This means that I can do 100 searches per day. Obviously, search results need to be recorded, and accumulate.\n",
    "* This Kiwix decision adds a lot of complexity to the zim-filter process. I will try to compartmentalize this complexity into a mostly self-contained set of cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "forward-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and restore youtube_id's corresponding to Kiwix's arbitrary ids\n",
    "lookup_yt_id = {}\n",
    "def recall_youtube_ids():\n",
    "    global lookup_yt_id\n",
    "    if not os.path.exists(CACHE_DIR + '/yt_id_from_kiwix_id'):\n",
    "        with open(CACHE_DIR + '/yt_id_from_kiwix_id','w') as fp:\n",
    "            fp.write(json.dumps('{}'))\n",
    "    with open(CACHE_DIR + '/yt_id_from_kiwix_id','r') as fp:\n",
    "        lookup_yt_id = json.loads(fp.read())\n",
    "        \n",
    "def save_youtube_ids():\n",
    "    with open(CACHE_DIR + '/yt_id_from_kiwix_id','w') as fp:\n",
    "        fp.write(json.dumps(lookup_yt_id,indent=2))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-maine",
   "metadata": {},
   "source": [
    "#### Pick the best Youtube answer to pick the best Youtube_id\n",
    "* Youtube returns many items that may differ in small ways from the search query submitted. We need to use fuzzy logic to pick the best match. \n",
    "* The longest string for match may be best (maybe description). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "northern-helena",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/iiab/jupyterhub/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IKdwdPk_scU\n"
     ]
    }
   ],
   "source": [
    "# Use the youtube API to get Id from string (description)\n",
    "from fuzzywuzzy import fuzz\n",
    "from  googleapiclient.discovery import build\n",
    "import googleapiclient.errors\n",
    "\n",
    "api_key = os.environ['API_KEY']\n",
    "os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "youtube = build(api_service_name, api_version, developerKey=api_key)\n",
    "\n",
    "def search_youtube(kiwix_id,project_name,description):\n",
    "    request = youtube.search().list(\n",
    "        part=\"id,snippet\",\n",
    "        type='video',\n",
    "        maxResults=10,\n",
    "        q=description\n",
    "    )\n",
    "    max_item = {}\n",
    "    max_value = 0\n",
    "    videoid = ''\n",
    "    response = request.execute()\n",
    "    #pprint(response)\n",
    "    for item in response['items']:\n",
    "        value = fuzz.ratio(item['snippet']['description'], description)\n",
    "        if value > max_value:\n",
    "            max_value = value\n",
    "            max_item = item\n",
    "    if max_item:\n",
    "        videoid = max_item['id']['videoId']\n",
    "        lookup_yt_id[kiwix_id] = {'project_name':project_name,\n",
    "                                  'youtube_id':videoid}\n",
    "        save_youtube_ids()\n",
    "    return videoid\n",
    "\n",
    "print(search_youtube(10,'test','We need to talk about an injustice | Bryan Stevenson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "appropriate-customer",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_assets_data():\n",
    "    # the file <root>/assets/data.js holds the category to video mappings\n",
    "    outstr = '['\n",
    "    data = {}\n",
    "    with open(PROJECT_DIR + '/assets/data.js', 'r') as fp:\n",
    "        line = fp.read()\n",
    "        if line[-1:] != ']':\n",
    "            line += ']'\n",
    "        if line.startswith('json_data'):\n",
    "            try:\n",
    "                data = json.loads(line[11:])\n",
    "            except Exception:\n",
    "                print('startswith json_data parse error:%s'%line[11:])\n",
    "                exit\n",
    "        else:\n",
    "            with open(PROJECT_DIR + '/assets/data.js', 'r') as fp:\n",
    "                line = fp.readline()\n",
    "                while True:\n",
    "                    if line.startswith('var') or not line :\n",
    "                        if len(outstr) > 3:\n",
    "                            # clip off the trailing semicolon\n",
    "                            outstr = outstr[:-2]\n",
    "                            try:\n",
    "                                data[category] = json.loads(outstr)\n",
    "                            except Exception:\n",
    "                                print('Parse error: %s'%outstr)\n",
    "                                exit\n",
    "                        category = line[9:-4]\n",
    "                        outstr = '['\n",
    "                        if not line: break\n",
    "                    else:\n",
    "                        outstr += line\n",
    "                    line = fp.readline()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sought-albert",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_ids(data):\n",
    "    # input data parameter is either a list or dict drawn for assets/data.js\n",
    "    # on return the youtube_id variable in data has valid youtube_id\n",
    "    global lookup_yt_ids\n",
    "    recall_youtube_ids()  # read the stored values\n",
    "    # if id is 11 char, use as youtube_id, otherwise look up from title\n",
    "    if isinstance(data,list):\n",
    "        for index in range(len(data)):\n",
    "            if len(data[index]['id']) == 11:\n",
    "                data[index]['youtube_id'] = data[index]['id']\n",
    "            else:\n",
    "                # videos in more than one category, don't look up more than once\n",
    "                kiwix_id = data[index]['id']\n",
    "                yt = lookup_yt_id.get(kiwix_id,'')\n",
    "                if yt == '':\n",
    "                    yt = search_youtube(kiwix_id,PROJECT_NAME,data[index]['description'][0]['text'])\n",
    "                else: # we may have more than one with this kiwix id\n",
    "                    if lookup_yt_id[kiwix_id]['project_name'] != PROJECT_NAME:\n",
    "                        # object and quit\n",
    "                        print('There are more than one kiwix ids with the value:%s'%kiwix_id)\n",
    "                        print('You need to delete the file at zims/youtube/cache/yt_id_from_kiwix_id and start over')\n",
    "                        sys.exit(0)\n",
    "                    else:\n",
    "                        yt = lookup_yt_id[kiwix_id]['youtube_id']\n",
    "                data[index]['youtube_id'] = yt\n",
    "    else: # data must be a dictionary of categories\n",
    "        for cat in data:\n",
    "            if len(data[cat]['id']) == 11:\n",
    "                data[cat]['youtube_id'] = data[cat]['id']\n",
    "            else:\n",
    "                # videos in more than one category, don't look up more than once\n",
    "                yt = lookup_yt_id.get(data[cat]['id'],'')\n",
    "                if yt == '':\n",
    "                    yt = search_youtube(data[cat]['title'])\n",
    "                data[cat]['youtube_id'] = yt\n",
    "    #pprint(data) \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "scenic-driving",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_js = get_assets_data()\n",
    "#print(json.dumps(data_js,indent=2))\n",
    "fix_ids(data_js) # Does a youtube search if id's are not youtube_ids\n",
    "def get_zim_data(kiwix_id):\n",
    "    rtn_dict = {}\n",
    "    if isinstance(data_js,list):\n",
    "        for video in range(len(data_js)):\n",
    "            if data_js[video]['id'] == kiwix_id:\n",
    "                rtn_dict = data_js[video]\n",
    "                break\n",
    "        return rtn_dict\n",
    "        \n",
    "    else:\n",
    "        for cat in  iter(data_js.keys()):\n",
    "            for video in range(len(data_js[cat])):\n",
    "                if data_js[cat][video]['id'] == kiwix_id:\n",
    "                    rtn_dict = data_js[cat][video]\n",
    "                    break\n",
    "            if len(rtn_dict) > 0: \n",
    "                break\n",
    "        return rtn_dict\n",
    "\n",
    "ans = get_zim_data('usdJgEwMinM')\n",
    "#print(json.dumps(ans,indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "latter-complement",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading metadata from Youtube\n",
      "11 skipped and 0 downloaded\n"
     ]
    }
   ],
   "source": [
    "ydl = youtube_dl.YoutubeDL()\n",
    "print('Downloading metadata from Youtube')\n",
    "downloaded = 0\n",
    "skipped = 0\n",
    "# Create a list of video id's (which may not be youtube_ids)\n",
    "kiwix_id_list = os.listdir(PROJECT_DIR + '/videos/')\n",
    "# And we also need a list of actual youtube ids.\n",
    "yt_id_list = []\n",
    "for id in iter(kiwix_id_list):\n",
    "    if len(id) == 11:\n",
    "        yt_id = id\n",
    "    else:\n",
    "        # The global lookup_yt_id contains the persistent youtube search result\n",
    "        yt_id = lookup_yt_id[id]['youtube_id']\n",
    "    yt_id_list.append(yt_id)\n",
    "    if os.path.exists(CACHE_DIR + '/video_json/' + yt_id + '.json'):\n",
    "        # skip over items that are already downloadd\n",
    "        skipped += 1\n",
    "        continue\n",
    "    with ydl:\n",
    "       result = ydl.extract_info(\n",
    "                'http://www.youtube.com/watch?v=%s'%yt_id,\n",
    "                download=False # We just want to extract the info\n",
    "                )\n",
    "       downloaded += 1\n",
    "\n",
    "    with open(CACHE_DIR + '/video_json/' + yt_id + '.json','w') as fp:\n",
    "        fp.write(json.dumps(result))\n",
    "    #pprint.pprint(result['upload_date'],result['view_count'])\n",
    "print('%s skipped and %s downloaded'%(skipped,downloaded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-charm",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Playlist Navigation to Videos\n",
    "* On the home page that shows when viewing a ZIM, there is a drop down selector which lists about 70 cateegories (or playlists).\n",
    "* The value from that drop down is used to pick an entry in \"-/assets/data.js\", which in turn specifies the  youtube ID\"s that are displayed when a selection is made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-executive",
   "metadata": {},
   "source": [
    "#### The following Cell is subroutines and can be left minimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "prospective-patient",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from pymediainfo import MediaInfo\n",
    "\n",
    "def mediainfo_dict(path):\n",
    "    try:\n",
    "        minfo = MediaInfo.parse(path)\n",
    "    except:\n",
    "        print('mediainfo_dict. file not found: %s'%path)\n",
    "        return {}\n",
    "    return minfo.to_data()\n",
    "\n",
    "def select_info(path):\n",
    "    global data\n",
    "    data = mediainfo_dict(path)\n",
    "    rtn = {}\n",
    "    infotrack = data.get('tracks',0)\n",
    "    if infotrack == 0:\n",
    "        return {}\n",
    "    for index in range(len(infotrack)):\n",
    "        #if index\n",
    "        track = data['tracks'][index]\n",
    "        if track['kind_of_stream'] == 'General':\n",
    "            rtn['file_size'] = track.get('file_size',0)\n",
    "            rtn['bit_rate'] = track.get('overall_bit_rate',0)\n",
    "            rtn['time'] = track['other_duration'][0]\n",
    "        if track['kind_of_stream'] == 'Audio':\n",
    "            rtn['a_stream'] = track.get('stream_size',0)\n",
    "            rtn['a_rate'] = track.get('maximum_bit_rate',0)\n",
    "            rtn['a_channels'] = track.get('channel_s',0)\n",
    "        if track['kind_of_stream'] == 'Video':\n",
    "            rtn['v_stream'] = track.get('stream_size',0)\n",
    "            rtn['v_format'] = track['other_format'][0]\n",
    "            rtn['v_rate'] = track.get('bit_rate',0)\n",
    "            rtn['v_frame_rate'] = track.get('frame_rate',0)\n",
    "            rtn['v_width'] = track.get('width',0)\n",
    "            rtn['v_height'] = track.get('height',0)\n",
    "    return rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rolled-flooring",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "class Sqlite():\n",
    "   def __init__(self, filename):\n",
    "      self.conn = sqlite3.connect(filename)\n",
    "      self.conn.row_factory = sqlite3.Row\n",
    "      self.conn.text_factory = str\n",
    "      self.c = self.conn.cursor()\n",
    "    \n",
    "   def __del__(self):\n",
    "      self.conn.commit()\n",
    "      self.c.close()\n",
    "      del self.conn\n",
    "\n",
    "def get_video_json(path):\n",
    "    with open(path,'r') as fp:\n",
    "        try:\n",
    "            jsonstr = fp.read()\n",
    "            #print(path)\n",
    "            modules = json.loads(jsonstr.strip())\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(jsonstr[:80])\n",
    "            return {}\n",
    "    return modules\n",
    "\n",
    "def video_size(kiwix_id):\n",
    "    return os.path.getsize(PROJECT_DIR + '/-/videos/' + kiwix_id + '/video.webm')\n",
    "\n",
    "def make_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def download_file(url,todir):\n",
    "    local_filename = url.split('/')[-1]\n",
    "    r = requests.get(url)\n",
    "    f = open(todir + '/' + local_filename, 'wb')\n",
    "    for chunk in r.iter_content(chunk_size=512 * 1024):\n",
    "        if chunk:\n",
    "            f.write(chunk)\n",
    "    f.close()\n",
    "    \n",
    "from datetime import datetime\n",
    "def age_in_years(upload_date):\n",
    "    uploaded_dt = datetime.strptime(upload_date,\"%Y%m%d\")\n",
    "    now_dt = datetime.now()\n",
    "    days_delta = now_dt - uploaded_dt\n",
    "    years = days_delta.days/365 + 1\n",
    "    return years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-professional",
   "metadata": {},
   "source": [
    "#### Create a sqlite database which collects Data about each Video\n",
    "* We've already downloaded the data from YouTube for each Video. So get the items that are interesing to us. Such as size,date uploaded to youtube,view count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "running-seminar",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating/Updating a Sqlite database with information about the Videos in this ZIM.\n",
      "/library/www/html/zims/trippy/working\n",
      "DOW2YTnzQBI 44957833 18 4 20180106 13 min 2 s 459434 VP8 0.0 a-scientific-approach-to-the-paranormal 4\n"
     ]
    }
   ],
   "source": [
    "def initialize_db():\n",
    "    sql = 'CREATE TABLE IF NOT EXISTS video_info ('\\\n",
    "            'yt_id TEXT UNIQUE, zim_size INTEGER, view_count INTEGER, age INTEGER, '\\\n",
    "            'views_per_year INTEGER, upload_date TEXT, duration TEXT, '\\\n",
    "            'height INTEGER, width INTEGER,'\\\n",
    "            'bit_rate TEXT, format TEXT, '\\\n",
    "            'average_rating REAL,slug TEXT, title TEXT, kiwix_id TEXT)'\n",
    "    db.c.execute(sql)\n",
    "\n",
    "print('Creating/Updating a Sqlite database with information about the Videos in this ZIM.')\n",
    "print(WORKING_DIR)\n",
    "db = Sqlite(WORKING_DIR + '/zim_video_info.sqlite')\n",
    "initialize_db()\n",
    "sql = 'select count() as num from video_info'\n",
    "db.c.execute(sql)\n",
    "row = db.c.fetchone()\n",
    "if row[0] == len(kiwix_id_list):\n",
    "    print('skipping update of sqlite database. Number of records equals number of videos')\n",
    "else:\n",
    "    for kiwix_id in iter(kiwix_id_list):\n",
    "        # some defaults\n",
    "        age = 0\n",
    "        views_per_year = 1\n",
    "        yt_id = lookup_yt_id[kiwix_id]['youtube_id']\n",
    "        # fetch data from assets/data.js\n",
    "        zim_data = get_zim_data(kiwix_id)\n",
    "        if len(zim_data) == 0: \n",
    "            print('get_zim_data returned no data for %s'%kiwix_id)\n",
    "        #pprint(zim_data)\n",
    "        slug = zim_data.get('slug','')\n",
    "\n",
    "        # We already have youtube data for every video, use it \n",
    "        data = get_video_json(CACHE_DIR + \"/video_json/\" + yt_id + '.json')\n",
    "        if len(data) == 0:\n",
    "            print('get_video_json returned no data for %s'%yt_id)\n",
    "        vsize = data.get('filesize',0)\n",
    "        view_count = data.get('view_count',0)\n",
    "        upload_date = data.get('upload_date','')\n",
    "        average_rating = data.get('average_rating',0)\n",
    "        title = data.get('title','unknown title')\n",
    "        # calculate the views_per_year since it was uploaded\n",
    "        if upload_date != '':\n",
    "            age = round(age_in_years(upload_date))\n",
    "            views_per_year = int(view_count / age)\n",
    "\n",
    "        # interogate the video itself\n",
    "        filename = PROJECT_DIR + '/videos/' + kiwix_id + '/video.webm'\n",
    "        if os.path.isfile(filename):\n",
    "            vsize = os.path.getsize(filename)\n",
    "            #print('vsize:%s'%vsize)\n",
    "            selected_data = select_info(filename)\n",
    "            if len(selected_data) == 0:\n",
    "                duration = \"not found\"\n",
    "                bit_rate = \"\" \n",
    "                v_format = \"\"\n",
    "                v_height = \"\"\n",
    "                v_width = \"\"\n",
    "            else:\n",
    "                duration = selected_data['time']\n",
    "                bit_rate = selected_data['bit_rate']\n",
    "                v_format = selected_data['v_format']\n",
    "                v_height = selected_data['v_height']\n",
    "                v_width = selected_data['v_width']\n",
    "\n",
    "        # colums names: yt_id,zim_size,view_count,views_per_year,upload_date,duration,\n",
    "        #         bit_rate, format,average_rating,slug,title,kiwix_id\n",
    "        sql = 'INSERT OR REPLACE INTO video_info VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)'\n",
    "        db.c.execute(sql,[yt_id,vsize,view_count,round(age),views_per_year,upload_date, \\\n",
    "                          duration,v_height,v_width,bit_rate,v_format,average_rating,slug,title,kiwix_id ])\n",
    "    db.conn.commit()\n",
    "    print(yt_id,vsize,view_count,views_per_year,upload_date, \\\n",
    "                          duration,bit_rate,v_format,average_rating,slug,round(age))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "senior-romantic",
   "metadata": {
    "tags": [
     "\"output_scroll\""
    ]
   },
   "source": [
    "sqlite_db = WORKING_DIR + '/zim_video_info.sqlite'\n",
    "!sqlite3 {sqlite_db} '.headers on' 'select * from video_info limit 4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-breathing",
   "metadata": {},
   "source": [
    "#### Select the cutoff using view count and total size\n",
    "* Order the videos by view countper year. Then select the sum line in the that has the target sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "suited-operation",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                        Name   Size    Sum  Views  Views   Date   Duration\n",
      "                                                                                    / yr                  \n",
      "    Reggie Watts disorients you in the most entertaining way  32.7M  32.7M  9.32M   954K 20120525 9 min 40 s\n",
      "                                    Ze Frank: Are you human?  14.2M  46.9M  1.39M   178K 20140718 4 min 34 s\n",
      "                        Your body is my canvas | Alexa Meade  22.7M  69.5M   296K  32.8K 20130906 7 min 4 s\n",
      "A Musical Escape Into a World of Light and Color | Kaki King  47.0M   116M   147K  24.5K 20151203 11 min 35 s\n",
      "             Psychedelic Science | Fabian Oefner | TED Talks  43.5M   160M   201K  22.3K 20131003 12 min 5 s\n",
      "                       Bruno Maisonnier: Dance, tiny robots!  12.7M   173M   120K  13.3K 20130226 3 min 6 s\n",
      "Quixotic Fusion dancers set to Serenity - HYPE RMX  feat Lau  37.8M   211M    841    120 20150410 12 min 19 s\n",
      "              The first Cyborg in the world - Neil Harbisson  37.1M   248M    128   25.0 20170726 9 min 32 s\n",
      "                      TED: Jae Rhim Lee-Mushroom burial suit  25.6M   273M    154   22.0 20150328 7 min 27 s\n",
      "                                         Symbiosis,God Music  68.0M   341M   15.0   7.00 20200310 13 min 45 s\n",
      "      A scientific approach to the paranormal | Carrie Poppy  42.9M   384M   18.0   4.00 20180106 13 min 2 s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display \n",
    "global tot_sum\n",
    "\n",
    "def human_readable(num):\n",
    "    # return 3 significant digits and unit specifier\n",
    "    num = float(num)\n",
    "    units = [ '','K','M','G']\n",
    "    for i in range(4):\n",
    "        if num<10.0:\n",
    "            return \"%.2f%s\"%(num,units[i])\n",
    "        if num<100.0:\n",
    "            return \"%.1f%s\"%(num,units[i])\n",
    "        if num < 1000.0:\n",
    "            return \"%.0f%s\"%(num,units[i])\n",
    "        num /= 1024.0\n",
    "\n",
    "sql = 'select title,zim_size,views_per_year,view_count,duration,upload_date,'\\\n",
    "       'format,width,height,bit_rate from video_info order by views_per_year desc'\n",
    "tot_sum = 0\n",
    "db.c.execute(sql)\n",
    "rows = db.c.fetchall()\n",
    "row_list = []\n",
    "boundary_views_per_year = 0\n",
    "for row in rows:\n",
    "    tot_sum += row['zim_size']\n",
    "    row_list.append([row['title'][:60],human_readable(row['zim_size']),\\\n",
    "                              human_readable(tot_sum),human_readable(row['view_count']),\\\n",
    "                              human_readable(row['views_per_year']),\\\n",
    "                              row['upload_date'],row['duration'],row['bit_rate']])\n",
    "    if tot_sum > TARGET_SIZE and boundary_views_per_year == 0:\n",
    "        boundary_views_per_year = row['views_per_year']\n",
    "print('%60s %6s %6s %6s %6s %8s %8s'%('Name','Size','Sum','Views','Views','Date  ','Duration'))\n",
    "print('%60s %6s %6s %6s %6s %8s %8s'%('','','','','/ yr','',''))\n",
    "tot_sum = 0\n",
    "for row in rows:\n",
    "    tot_sum += row['zim_size']\n",
    "    print('%60s %6s %6s %6s %6s %8s %8s'%(row['title'][:60],human_readable(row['zim_size']),\\\n",
    "                              human_readable(tot_sum),human_readable(row['view_count']),\\\n",
    "                              human_readable(row['views_per_year']),\\\n",
    "                              row['upload_date'],row['duration']))\n",
    "#df = pd.read_sql(sql,db.conn)\n",
    "#df = pd.DataFrame(row_list,columns=['Name','Size','Sum','Views','Views','Date','Duration','Bit Rate'])\n",
    "#display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-front",
   "metadata": {
    "tags": []
   },
   "source": [
    "* Now determine the video ID's that we want in our new zim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "maritime-memorial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will include videos with views_per_year greater than 0\n"
     ]
    }
   ],
   "source": [
    "print('We will include videos with views_per_year greater than %s'%boundary_views_per_year)\n",
    "wanted_ids = []\n",
    "sql = 'SELECT kiwix_id, title from video_info where views_per_year > ?'\n",
    "db.c.execute(sql,[boundary_views_per_year,])\n",
    "rows = db.c.fetchall()\n",
    "for row in rows:\n",
    "    wanted_ids.append(row['kiwix_id'])\n",
    "\n",
    "#with open(HOME + '/zims/' + PROJECT_NAME + '/wanted_list.csv','w') as fp:\n",
    "#    for row in rows:\n",
    "#        fp.write('%s,%s\\n'%(row['yt_id'],row['title'],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "smart-kennedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2366',\n",
       " '2049',\n",
       " '1512',\n",
       " '1834',\n",
       " '1458',\n",
       " '1677',\n",
       " '1247',\n",
       " '1814',\n",
       " '24',\n",
       " '1464',\n",
       " '2702']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wanted_ids"
   ]
  },
  {
   "cell_type": "raw",
   "id": "catholic-affiliate",
   "metadata": {},
   "source": [
    "* Now let's start building up the output directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "alternate-script",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying wanted folders and Videos to /library/www/html/zims/trippy/output_tree\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "# copy the default top level directories (these were in the zim's \"-\" directory )\n",
    "print('Copying wanted folders and Videos to %s'%OUTPUT_DIR)\n",
    "cpy_dirs = ['assets','cache','channels']\n",
    "for d in cpy_dirs:\n",
    "    shutil.rmtree(os.path.join(OUTPUT_DIR,d),ignore_errors=True)\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR,d))\n",
    "    src = os.path.join(PROJECT_DIR,d)\n",
    "    dest = os.path.join(OUTPUT_DIR,d)\n",
    "    if os.path.exists(src):\n",
    "        shutil.copytree(src,dest,dirs_exist_ok=True, symlinks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "expected-collaboration",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy the videos selected by the wanted_ids list to output file\n",
    "import shutil\n",
    "for f in wanted_ids:\n",
    "    if not os.path.isdir(os.path.join(OUTPUT_DIR,'videos',f)):\n",
    "        os.makedirs(os.path.join(OUTPUT_DIR,'videos',f))\n",
    "        src = os.path.join(PROJECT_DIR,'videos',f)\n",
    "        dest = os.path.join(OUTPUT_DIR,'videos',f)\n",
    "        shutil.copytree(src,dest,dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "divided-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Copy the files in the root directory\n",
    "import shutil\n",
    "for kiwix_id in wanted_ids:\n",
    "    map_index_to_slug = get_zim_data(kiwix_id)\n",
    "    if len(map_index_to_slug) > 0:\n",
    "        title = map_index_to_slug.get('slug','')\n",
    "        if title == '':\n",
    "            title = kiwix_id\n",
    "        src = os.path.join(PROJECT_DIR,title)\n",
    "        dest = OUTPUT_DIR + '/' + title\n",
    "    if os.path.isfile(src) and not os.path.isfile(dest):\n",
    "        shutil.copyfile(src,dest)\n",
    "    else:\n",
    "        print('src:%s'%src)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "statutory-abraham",
   "metadata": {
    "tags": []
   },
   "source": [
    "wanted_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "horizontal-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are essential files that are needed in the zim\n",
    "needed = ['/favicon.png','/favicon.jpg','/home.html',\\\n",
    "          '/index','/profile.jpg','/index.html']\n",
    "for f in needed:\n",
    "    if os.path.exists(PROJECT_DIR  + f):\n",
    "        cmd = '/bin/cp %s %s'%(PROJECT_DIR  + f,OUTPUT_DIR)\n",
    "        subprocess.run(cmd,shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "confidential-handy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Counter': 'video/webm=11;image/webp=22;text/vtt=356;text/html=13;application/font-sfnt=6;text/css=6;application/javascript=83;text/plain=8;application/octet-stream=15;application/x-shockwave-flash=1;text/markdown=1;image/svg+xml=1;application/json=41;image/png=5',\n",
      " 'Creator': 'TED',\n",
      " 'Date': '2021-01-19',\n",
      " 'Description': 'These surprising, slightly psychedelic talks are better than '\n",
      "                'staring at a blacklight poster.',\n",
      " 'IndexLanguage': 'eng',\n",
      " 'Language': 'eng',\n",
      " 'Name': 'ted_en_playlist-9-trippy-ted-talks',\n",
      " 'Publisher': 'Kiwix',\n",
      " 'Scraper': 'ted2zim 2.0.8',\n",
      " 'Tags': '_category:ted;ted;_videos:yes',\n",
      " 'Title': '11 trippy TED Talks'}\n"
     ]
    }
   ],
   "source": [
    "# Grab the meta data from the original zim \"M\" directory \n",
    "#   and create a script for zimwriterfs\n",
    "def get_file_value(path):\n",
    "    with open(path,'r') as fp:\n",
    "        \n",
    "        try:\n",
    "            return fp.read()\n",
    "        except:\n",
    "            return \"\"\n",
    "meta_data ={}\n",
    "meta_file_names = os.listdir(PROJECT_DIR + '/M/')\n",
    "for f in meta_file_names:\n",
    "    meta_data[f] = get_file_value(PROJECT_DIR + '/M/' + f)\n",
    "pprint(meta_data)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "regional-paragraph",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new mapping from Categories to videos within each category.\n"
     ]
    }
   ],
   "source": [
    "# Write a new mapping from categories to vides (with some removed)\n",
    "print('Creating a new mapping from Categories to videos within each category.')\n",
    "outstr = ''\n",
    "if isinstance(data_js,list):\n",
    "    json_data = []  \n",
    "    outstr += 'json_data = ['\n",
    "    for index in range(len(data_js)):\n",
    "        item_dict = data_js[index]\n",
    "        if not item_dict['id'] in wanted_ids: continue\n",
    "        outstr += json.dumps(item_dict,indent=2)\n",
    "        outstr += ','\n",
    "    outstr = outstr[:-1] + ']'\n",
    "else:\n",
    "    for cat in zim_category_js:\n",
    "        outstr += 'var json_%s = [\\n'%cat\n",
    "        for video in range(len(zim_category_js[cat])):\n",
    "            if zim_category_js[cat][video].get('id','') in wanted_ids:\n",
    "                outstr += json.dumps(zim_category_js[cat][video],indent=1)\n",
    "                outstr += ','\n",
    "        outstr = outstr[:-1]\n",
    "        outstr += '];\\n'\n",
    "with open(OUTPUT_DIR + '/assets/data.js','w') as fp:\n",
    "    fp.write(outstr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-cigarette",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "radio-crazy",
   "metadata": {},
   "source": [
    "\n",
    "mk_zim_cmd = \"\"\"\n",
    "zimwriterfs --language=eng\\\n",
    "            --welcome=A/home.html\\\n",
    "            --favicon=I/favicon.jpg\\\n",
    "            --title=teded_en_%s\\\n",
    "            --description=\\\"TED-Ed Videos from YouTube Channel\\\"\\\n",
    "            --creator='Youtube Channel “TED-Ed”'\\\n",
    "            --publisher=IIAB\\\n",
    "            --name=TED-Ed\\\n",
    "             %s %s.zim\"\"\"%(PROJECT_NAME,OUTPUT_DIR,PROJECT_NAME)\n",
    "#with open(HOME + '/zims/' + PROJECT_NAME + '-zimwriter-cmd.sh','w') as fp:\n",
    "#    fp.write(mk_zim_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "advance-cream",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new ZIM and Indexing it\n",
      "fname:ted_en_playlist-9-trippy-ted-talks_2021-01.zim\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Traceback (most recent call last):\n  File \"libzim/wrapper.pyx\", line 121, in libzim.wrapper.blob_cy_call_fct\n  File \"/opt/iiab/jupyterhub/lib/python3.8/site-packages/libzim/writer.py\", line 88, in _get_data\n    self._blob = self.get_data()\n  File \"/opt/iiab/jupyterhub/lib/python3.8/site-packages/zimscraperlib/zim/filesystem.py\", line 110, in get_data\n    rewriter(self.fpath, root=self.root).encode(\"utf-8\")\n  File \"/opt/iiab/jupyterhub/lib/python3.8/site-packages/zimscraperlib/zim/rewriting.py\", line 221, in fix_links_in_html_file\n    return fix_links_in_html(url, fh.read())\n  File \"/opt/iiab/jupyterhub/lib/python3.8/site-packages/zimscraperlib/zim/rewriting.py\", line 191, in fix_links_in_html\n    fixed = fix_target_for(\n  File \"/opt/iiab/jupyterhub/lib/python3.8/site-packages/zimscraperlib/zim/rewriting.py\", line 130, in fix_target_for\n    flat_target = flat_target.resolve().relative_to(root.resolve())\n  File \"/usr/lib/python3.8/pathlib.py\", line 904, in relative_to\n    raise ValueError(\"{!r} does not start with {!r}\"\nValueError: '/hd/library/www/html/zims/trippy/I/favicon.png' does not start with '/hd/library/www/html/zims/trippy/output_tree'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-6721ace451e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mfavicon_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'favicon.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNEW_ZIM_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     make_zim_file(\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mbuild_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mfpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNEW_ZIM_DIR\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/iiab/jupyterhub/lib/python3.8/site-packages/zimscraperlib/zim/filesystem.py\u001b[0m in \u001b[0;36mmake_zim_file\u001b[0;34m(build_dir, fpath, name, main_page, favicon, title, description, date, language, creator, publisher, tags, source, flavour, scraper, without_fulltext_index, redirects, redirects_file, rewrite_links, workaround_nocancel)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;31m# recursively add content from build_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Recursively adding files from {build_dir}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0madd_to_zim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzim_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewrite_links\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mredirects\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mredirects_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/iiab/jupyterhub/lib/python3.8/site-packages/zimscraperlib/zim/filesystem.py\u001b[0m in \u001b[0;36madd_to_zim\u001b[0;34m(root, zim_file, fpath, rewrite_links)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mleaf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"... [FILE] {leaf}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0madd_to_zim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzim_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewrite_links\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\".. [FILE] {fpath}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/iiab/jupyterhub/lib/python3.8/site-packages/zimscraperlib/zim/filesystem.py\u001b[0m in \u001b[0;36madd_to_zim\u001b[0;34m(root, zim_file, fpath, rewrite_links)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\".. [FILE] {fpath}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileArticle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewrite_links\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mzim_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_zim_article\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/iiab/jupyterhub/lib/python3.8/site-packages/zimscraperlib/zim/creator.py\u001b[0m in \u001b[0;36madd_zim_article\u001b[0;34m(self, article)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;34m\"\"\" Add a libzim.writer Article \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_article\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkaround_nocancel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/iiab/jupyterhub/lib/python3.8/site-packages/libzim/writer.py\u001b[0m in \u001b[0;36madd_article\u001b[0;34m(self, article)\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mRuntimeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                     If the ZimCreator was already finalized \"\"\"\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_creatorWrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_article\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_redirect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;31m# update article counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/iiab/jupyterhub/lib/python3.8/site-packages/libzim/wrapper.pyx\u001b[0m in \u001b[0;36mlibzim.wrapper.Creator.add_article\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Traceback (most recent call last):\n  File \"libzim/wrapper.pyx\", line 121, in libzim.wrapper.blob_cy_call_fct\n  File \"/opt/iiab/jupyterhub/lib/python3.8/site-packages/libzim/writer.py\", line 88, in _get_data\n    self._blob = self.get_data()\n  File \"/opt/iiab/jupyterhub/lib/python3.8/site-packages/zimscraperlib/zim/filesystem.py\", line 110, in get_data\n    rewriter(self.fpath, root=self.root).encode(\"utf-8\")\n  File \"/opt/iiab/jupyterhub/lib/python3.8/site-packages/zimscraperlib/zim/rewriting.py\", line 221, in fix_links_in_html_file\n    return fix_links_in_html(url, fh.read())\n  File \"/opt/iiab/jupyterhub/lib/python3.8/site-packages/zimscraperlib/zim/rewriting.py\", line 191, in fix_links_in_html\n    fixed = fix_target_for(\n  File \"/opt/iiab/jupyterhub/lib/python3.8/site-packages/zimscraperlib/zim/rewriting.py\", line 130, in fix_target_for\n    flat_target = flat_target.resolve().relative_to(root.resolve())\n  File \"/usr/lib/python3.8/pathlib.py\", line 904, in relative_to\n    raise ValueError(\"{!r} does not start with {!r}\"\nValueError: '/hd/library/www/html/zims/trippy/I/favicon.png' does not start with '/hd/library/www/html/zims/trippy/output_tree'\n"
     ]
    }
   ],
   "source": [
    "print('Creating a new ZIM and Indexing it')\n",
    "\n",
    "from pathlib import Path\n",
    "from zimscraperlib.zim import make_zim_file\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "\n",
    "original_name = glob(\"%s/*.zim\"%(SOURCE_DIR))\n",
    "fname = os.path.basename(original_name[0].replace('all','top'))\n",
    "print('fname:%s'%fname)\n",
    "#sys.exit(1)\n",
    "\n",
    "os.chdir(OUTPUT_DIR)\n",
    "if os.path.exists(OUTPUT_DIR + '/favicon.png'):\n",
    "    favicon_fn = 'favicon.png'\n",
    "else:\n",
    "    favicon_fn = 'favicon.jpg'\n",
    "if not os.path.isfile(os.path.join(NEW_ZIM_DIR,fname)):\n",
    "    make_zim_file(\n",
    "        build_dir=Path(OUTPUT_DIR),\n",
    "        fpath=Path(NEW_ZIM_DIR) / fname,\n",
    "        name=fname,\n",
    "        main_page= \"home.html\",\n",
    "        favicon=favicon_fn,\n",
    "        title=meta_data['Title'],\n",
    "        description=meta_data['Description'],\n",
    "        language=meta_data['Language'],\n",
    "        creator=meta_data['Creator'],\n",
    "        publisher=\"Internet In A Box\",\n",
    "        tags=meta_data['Tags'],\n",
    "        scraper=meta_data['Scraper'],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-deviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the zim file to get the metadata accumulated during it's creation\n",
    "cmd = f'zimdump dump --dir={PROOF_DIR} {NEW_ZIM_DIR}/{fname}'\n",
    "subprocess.run(cmd,shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dict with the counts of file mime types in the ZIM\n",
    "with open(f'{PROOF_DIR}/M/Counter','r') as fp:\n",
    "    counts = fp.read().split(';')\n",
    "countdict = {}\n",
    "for nibble in counts:\n",
    "    nibble = nibble.split('=')\n",
    "    countdict[nibble[0]] = nibble[1]\n",
    "pprint(countdict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the uuid from the new zim\n",
    "cmd = f'zimdump info {NEW_ZIM_DIR}/{fname}'\n",
    "infodump = subprocess.run(cmd,shell=True,capture_output=True)\n",
    "lines = infodump.stdout.decode('utf-8').split('\\n')\n",
    "for line in lines:\n",
    "    if line.split(' ')[0] == 'uuid:':\n",
    "        uuid = line.split(' ')[1].strip()\n",
    "if not uuid:\n",
    "    print('failed to get uuid')\n",
    "else:\n",
    "    print(\"uuid:%s\"%uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a catalog fragment for this video\n",
    "import base64\n",
    "uuidstr = uuid\n",
    "CATALOG_FRAG_DIR = '/opt/iiab/iiab-content/catalogs/zim-cat-fragments'\n",
    "WASABI_URL = 'https://s3.us-east-2.wasabisys.com/iiab-zims'\n",
    "# Maintain the order of the zim catalog\n",
    "cat_keys = ['path','title','description','language','creator','publisher','tags','favicomMimeType',\n",
    "           'favicon','date','articleCount','mediaCount','size','url','name','flavour']\n",
    "outstr = '{\"%s\": {\\n'%uuidstr\n",
    "outstr += f'\"path\": \"../library/zims/content/{fname}\",\\n'\n",
    "outstr += f'\"title\": \"{meta_data[\"Title\"]}\",\\n'\n",
    "outstr += f'\"description\": \"{meta_data[\"Description\"]}\",\\n'\n",
    "outstr += f'\"language\": \"{meta_data[\"Language\"]}\",\\n'\n",
    "outstr += f'\"creator\": \"{meta_data[\"Creator\"]}\",\\n'\n",
    "outstr += f'\"publisher\": \"Internet In A box\",\\n'\n",
    "outstr += f'\"tags\": \"{meta_data[\"Tags\"]}\",\\n'\n",
    "outstr += f'\"faviconMimeType\": \"image/png\",\\n'\n",
    "with open(PROJECT_DIR + '/' + favicon_fn,'rb') as fp:\n",
    "    favi = fp.read()\n",
    "b64 = base64.b64encode(favi)\n",
    "outstr += f'\"favicon\": \"{b64}\",\\n'\n",
    "outstr += f'\"date\": \"{meta_data[\"Date\"]}\",\\n'\n",
    "outstr += f'\"articleCount\": \"{countdict[\"text/html\"]}\",\\n'\n",
    "outstr += f'\"mediaCount\": \"{countdict[\"video/webm\"]}\",\\n'\n",
    "size = os.path.getsize(f'{NEW_ZIM_DIR}/{fname}')\n",
    "outstr += f'\"size\": \"{size}\",\\n'\n",
    "outstr += f'\"url\": \"{WASABI_URL}/{fname}\",\\n'\n",
    "outstr += f'\"name\": \"{meta_data[\"Name\"]}\",\\n'\n",
    "outstr += f'\"flavour\": \"\"\\n'\n",
    "outstr += '}}'\n",
    "cat_fragment = '%s/%s'%(CATALOG_FRAG_DIR,fname.replace('.zim','.json'))\n",
    "with open(cat_fragment,'w') as fp:\n",
    "    fp.write(outstr)\n",
    "print(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now parse the file we just created to validate the json\n",
    "with open(cat_fragment,'r') as fp:\n",
    "    json_str = fp.read()\n",
    "frag_dict = json.loads(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-frost",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now recreate the iiab-zim-catalog by updating from zim fragments\n",
    "from glob import glob\n",
    "import json\n",
    "CATALOG_FRAG_DIR = '/opt/iiab/iiab-content/catalogs/zim-cat-fragments'\n",
    "ZIM_CATALOG = '/opt/iiab/iiab-content/catalogs/iiab-zim-cat.json'\n",
    "with open(ZIM_CATALOG,'r') as zcat:\n",
    "    zim_dict = json.loads(zcat.read())\n",
    "frags = glob(CATALOG_FRAG_DIR + '/*.json')\n",
    "for frag in frags:\n",
    "    with open(frag,'r') as fp:\n",
    "        frag_dict = json.loads(fp.read())\n",
    "    zim_dict.update(frag_dict)\n",
    "with open(ZIM_CATALOG,'w') as zcat:\n",
    "    zcat.write(json.dumps(zim_dict,indent=2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-hygiene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the Zim Catalog\n",
    "ZIM_CATALOG = '/opt/iiab/iiab-content/catalogs/iiab-zim-cat.json'\n",
    "\n",
    "with open(ZIM_CATALOG,'r') as zcat:\n",
    "    try:\n",
    "        valid_dict = json.loads(zcat.read())\n",
    "    except Exception:\n",
    "        print('ZIM cataloge does not parse')\n",
    "        sys.exit(1)\n",
    "    print('ZIM catalog parsed successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-thesis",
   "metadata": {},
   "source": [
    "#### Notes on Install to VirtualBox Ubuntu20.04\n",
    "1. When I ran the IIAB jupyterhub role, I got a combination of Python packages that did not work.\n",
    "2. I went to an earlier installed Ubuntu20.04 install (in a virtualenv) that did work, and executed ```pip freeze > requirements.txt```. \n",
    "3. Transferred the requirements.txt file to the failing vBox instance, activated the venv ```source /opt/iiab/jupyberhub/bin/activate```, and ```pip install -r requirements.txt```. Then the iiab-factory/content/kiwix/zim-filter/start_remote_notebook.sh``` worked\n",
    "4. So the requirements.txt may be required until jupyterhub is fixed. It is in the repo in the same place as the noteboot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-positive",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-current",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
